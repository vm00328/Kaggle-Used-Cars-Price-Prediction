{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hlTVezAPUDJN"
   },
   "source": [
    "# WORKFLOW\n",
    "\n",
    "## Step 1: Importing Libraries & The Original Data\n",
    "\n",
    "---\n",
    "\n",
    "## Step 2: Exploratory Data Analysis: Understanding the Original Data\n",
    "\n",
    "**We will analyse and plot:**\n",
    "\n",
    "2.1.   the number of cars per brand to get a feeling of the distirbution of the dataset under the *'brand'* column\n",
    "\n",
    "2.2.   the distribution of the model year\n",
    "\n",
    "2.3.   the distribution of the milage\n",
    "\n",
    "2.4.   the distribution of prices\n",
    "\n",
    "2.5.   the various fuel types, engines, and transmissions\n",
    "\n",
    "2.6.   the vehicles with a reported accident vs those that have not reported one\n",
    "\n",
    "---\n",
    "\n",
    "## Step 3: Data Cleaning, Pre-Processing & Feature Engineering\n",
    "\n",
    "3.1   removal of redundant features following the EDA\n",
    "\n",
    "3.2   dropping records with limited statistical importance while ensuring this does not result in a certain class being underrepresented, subsequently leading to an imbalanced dataset\n",
    "\n",
    "3.3. Missing data under the Engine Volume, HP, and/or Cylinders columns and the car is electric, the former and the latter will be set to 0.\n",
    "\n",
    "3.4. We drop the 'clean_title' column since it contains a single unique value across all records and hence adds no value\n",
    "\n",
    "3.5. We drop the interior and exterior colour columns as they are believed to not add any statistical significance and are irrelevant given the project scope\n",
    "\n",
    "3.6. categorical brackets for some numeric data to decrease dimensionality\n",
    "\n",
    "3.7. We create new columns \"Engine Volume\", \"HP\", \"Cylinders\" by using the available data under the 'engine' column where that is applicable\n",
    "\n",
    "---\n",
    "\n",
    "## Step 4: Exploring the new features and cleaning if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "0uoz840Gr84M",
    "outputId": "da525f01-6eb1-452e-cb00-4e29ccd65c8b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data Pre-Processing\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Model Training\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Model Evaluation\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "sns.set(style = 'whitegrid')\n",
    "sns.set_context('notebook')\n",
    "\n",
    "data = pd.read_csv(r'C:\\Users\\VladislavManolo\\OneDrive - MIP\\Documenten\\GitHub\\Kaggle-Used-Cars-Price-Prediction\\data\\train.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZq_XVFeQ87Y"
   },
   "source": [
    "# Step 2: Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "XBUaGCpF0z8Z",
    "outputId": "784f7a4a-5e70-4d2a-e54f-b6e8d848c922"
   },
   "outputs": [],
   "source": [
    "# the 20 brands with the most presence in the dataset\n",
    "print(\"Number of cars: \", data.shape[0])\n",
    "print(\"Number of brands: \", data['brand'].nunique())\n",
    "\n",
    "sns.countplot(data = data, y = 'brand', order = data['brand'].value_counts().iloc[:20].index)\n",
    "plt.title('Top 20: Most Cars per Brand')\n",
    "plt.xlabel('Number of Cars')\n",
    "plt.ylabel('Brand')\n",
    "plt.show()\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "# the 20 brands with the least presence in the dataset\n",
    "sns.countplot(data = data, y = 'brand', order = data['brand'].value_counts().iloc[-20:].index)\n",
    "plt.title('Top 20: Fewest Cars per Brand')\n",
    "plt.xlabel('Number of Cars')\n",
    "plt.ylabel('Brand')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8-M5YrBgGO9"
   },
   "source": [
    "## 2.2. Model Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "E1wN7AlwgFta",
    "outputId": "07f8ced6-bf2e-44e7-fe84-58cb6a50d2ba"
   },
   "outputs": [],
   "source": [
    "# a histogram of the distirbution of the model year\n",
    "sns.histplot(data['model_year'], kde = True, bins = 50)\n",
    "plt.axvline(data['model_year'].mean(), color='red', linestyle='--', label = 'Average Year')\n",
    "plt.title('Distribution Plot for Model Year')\n",
    "plt.xlabel('Model Year')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wu598REogJy9"
   },
   "source": [
    "## 2.3. Milage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "l6jJ-VCxgHX0",
    "outputId": "7916f848-8178-4ea7-9e75-4a349022750c"
   },
   "outputs": [],
   "source": [
    "# average mileage and price for each brand\n",
    "brand_avg = data.groupby('brand', as_index = False).agg({'milage': 'mean', 'price': 'mean'})\n",
    "\n",
    "# interactive plot\n",
    "fig = px.scatter(brand_avg,\n",
    "                 text='brand',\n",
    "                 x='milage',\n",
    "                 y='price',\n",
    "                 title='Average Milage vs. Price by Brand',\n",
    "                 labels={'mileage': 'Average Milage', 'price': 'Average Price'})\n",
    "\n",
    "# marker size and label position\n",
    "fig.update_traces(marker = dict(size = 4), textposition = 'top right', textfont_size = 9)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3he-WfkgIlS"
   },
   "source": [
    "## 2.4. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "76VOhqJqgIQ-",
    "outputId": "485fd935-5ea3-4656-eb5a-58ffb3ccdbf3"
   },
   "outputs": [],
   "source": [
    "# a histogram of the distirbution of the price\n",
    "sns.histplot(data['price'], kde = True, bins = 50)\n",
    "plt.axvline(data['price'].mean(), color='red', linestyle='--', label = 'Average Price')\n",
    "plt.title('Distribution Plot for Model Year')\n",
    "plt.xlabel('Price')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SOFuTxWVgYBW"
   },
   "source": [
    "## 2.5. Price vs Model Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "Rp0PdpO1gaGg",
    "outputId": "58cf03cf-b238-4ab3-d5b4-97eebfa0cc29"
   },
   "outputs": [],
   "source": [
    "sns.lineplot(data = data, x = 'model_year', y = 'price')\n",
    "plt.title('Price vs. Model Year')\n",
    "plt.xlabel('Model Year')\n",
    "plt.ylabel('Price')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jgv-70F-TfJy"
   },
   "source": [
    "## 2.6. Fuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "_vcbaITz2Wqa",
    "outputId": "04d0b8d9-f62d-4c3e-d5dd-d148c78004f9"
   },
   "outputs": [],
   "source": [
    "# understanding the number of fuels across all vehicles\n",
    "print(data.fuel_type.value_counts())\n",
    "\n",
    "data[data['fuel_type'] ==  '–']['engine'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTI2xK4zk3je"
   },
   "source": [
    "**Intermediate conclusion:**\n",
    "\n",
    "*Missing data under the engine column, not necessarily as a NaN but as a '–' results in such under the 'fuel_type' column as well.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6gDzo6Ug2Oz"
   },
   "source": [
    "## 2.7. Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oW6mBb9OiBb7",
    "outputId": "c1510643-48c5-45a0-d12f-08b50c28ea2b"
   },
   "outputs": [],
   "source": [
    "print(\"NaN values under the Engine column: \", data.engine.isna().sum())\n",
    "\n",
    "data.engine.value_counts().sort_values(ascending = False)\n",
    "\n",
    "electric_cars = data[data['engine'].str.contains('electric', case=False, na=False)]['engine'].count()\n",
    "print(electric_cars)\n",
    "\n",
    "# electric engines\n",
    "electric_engines_counts = data[data['engine'].str.contains('electric', case=False, na=False)]['engine'].value_counts(ascending=False)\n",
    "electric_engines_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print unique engine names with less than 10 characters\n",
    "unique_engines_under_x_chars = [engine for engine in data['engine'].dropna().unique() if len(engine) < 20]\n",
    "\n",
    "engine_counts_under_x_chars = data[data['engine'].isin(unique_engines_under_x_chars)]['engine'].value_counts()\n",
    "engine_counts_under_x_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many engines have 0HP declared under the 'engine' column. For electric vehicles HP shall be replaced with kW if such is applicable. \n",
    "\n",
    "For non-electric vehicles, it needs to be handled accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2GbrId1e6CP"
   },
   "source": [
    "## 2.8. Transmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9mgZbmf6e5XS",
    "outputId": "2140a518-9ff0-49b8-916d-76c30695e6af"
   },
   "outputs": [],
   "source": [
    "# set Manual to M/T\n",
    "data['transmission'] = data['transmission'].replace('Manual', 'M/T')\n",
    "\n",
    "# understanding the number of transmissions across all vehicles\n",
    "print(data.transmission.value_counts().sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dyvBaGaMRnbI"
   },
   "source": [
    "# Step 3: Data Cleaning, Pre-Processing & Feature Engineering\n",
    "\n",
    "## 3.1. Addressing *fuel_type* data quality issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "id": "QdwG5LtwQ1t6",
    "outputId": "3f6bd905-c3ff-459a-a4e0-41906b90e3a6"
   },
   "outputs": [],
   "source": [
    "# fill under the 'fuel_type' column with the value 'Gasoline' if the word 'Gasoline' is mentioned under the 'engine' column\n",
    "data.loc[data['engine'].str.contains('Gasoline', case = False), 'fuel_type'] = 'Gasoline'\n",
    "\n",
    "# fill under the 'fuel_type' column with the value 'Hydrogen' if the word 'Hydrogen' is mentioned under the 'engine' column\n",
    "data.loc[data['engine'].str.contains('Hydrogen', case = False), 'fuel_type'] = 'Hydrogen'\n",
    "\n",
    "# drop records under the engine column where the value is '–'\n",
    "data = data[data['engine'] != '–']\n",
    "\n",
    "data.fuel_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZaF77DVroO4M"
   },
   "source": [
    "Addressing the last 2 remaining records labeled as '–' under the 'fuel_type' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "VhSb6ll4nHtA",
    "outputId": "0f1293a2-eac8-4379-8c88-ee791e306efa"
   },
   "outputs": [],
   "source": [
    "data[data['fuel_type'] == '–']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "m-NzkQRpnkba",
    "outputId": "b093e7e0-63f4-48a1-f230-dbf9d1b2a483"
   },
   "outputs": [],
   "source": [
    "# make the two remaining records with '–' udner the 'fuel_type' column be 'Gasoline'\n",
    "data.loc[data['fuel_type'] == '–', 'fuel_type'] = 'Gasoline'\n",
    "data[data['fuel_type'] == '–']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "41HEnq2HoFSM"
   },
   "source": [
    "Addressing the last remaining record labeled as 'not supported' under the 'fuel_type' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "BOshU1IDoEU8",
    "outputId": "a833e30f-6bd6-4362-8b70-39ff4332c019"
   },
   "outputs": [],
   "source": [
    "data[data['fuel_type'] == 'not supported']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "0oL8enYtoLZA",
    "outputId": "566d6f7b-4231-4518-ef49-3056550b81b5"
   },
   "outputs": [],
   "source": [
    "data.loc[data['fuel_type'] == 'not supported', 'fuel_type'] = 'Gasoline'\n",
    "data[data['fuel_type'] == 'not supported']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "CnfyRqoNsJHZ",
    "outputId": "d44670c5-04eb-437f-8ef6-6d91a40cda50"
   },
   "outputs": [],
   "source": [
    "# Assuming df is your DataFrame and 'engine' is the column with engine descriptions\n",
    "data.loc[data['engine'].str.contains('electric', case=False, na=False), 'fuel_type'] = 'Electric'\n",
    "data.dropna(subset=['fuel_type'], inplace=True)\n",
    "\n",
    "print(\"Remaining NaN columns under the 'fuel_type' column: \", data.fuel_type.isna().sum())\n",
    "data.fuel_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJk3P8-2tHjn"
   },
   "source": [
    "## 3.2. Dropping redundant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1iexDDJBtMH1"
   },
   "outputs": [],
   "source": [
    "# dropping redundant columns\n",
    "data.drop(columns = ['clean_title', 'int_col', 'ext_col'], inplace = True)\n",
    "\n",
    "# addressing inconsistensies among Tesla vehicles\n",
    "data.loc[(data['brand'] == 'Tesla') & ( (data['fuel_type'] == 'Gasoline') | (data['fuel_type'] == 'Diesel') ), 'fuel_type'] = 'Electric'\n",
    "\n",
    "# retrieving the HP, engine volume, and cylinders of each vehicle if such information exists under the 'engine' column\n",
    "data['HP'] = data['engine'].str.extract('(\\d+)\\.?\\d*HP') #fillna('NA')\n",
    "data['Engine Volume (Liters)'] = data['engine'].str.extract('(\\d+\\.?\\d*)L')\n",
    "data['Cylinders'] = data['engine'].str.extract('(\\d+)\\s*Cylinder|V(\\d+)').bfill(axis=1).iloc[:, 0]\n",
    "data.drop(columns = ['engine'], inplace = True)\n",
    "\n",
    "print(f\"Dataframe shape: {data.shape}\")\n",
    "\n",
    "print(data.isna().sum(), '\\n')\n",
    "\n",
    "print(data.dtypes, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXxiW5Y0pA5z"
   },
   "source": [
    "### 3.3. Milage & Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "1L9olIoqQixe",
    "outputId": "c5848458-5786-4aad-b159-a1678d87b64d"
   },
   "outputs": [],
   "source": [
    "####################################################### milage & price categorical labels #######################################################\n",
    "milage_brackets = [100, 25000, 58000, 95000, float('inf')]\n",
    "milage_labels = ['Low Milage (100-25k)', 'Low-to-Medium Milage (25k-58k)', 'Medium-to-High Milage (58k-95k)', 'High Milage (95k+)']\n",
    "\n",
    "price_brackets = [2000, 17000, 31000, 50000, float('inf')]\n",
    "price_labels = ['Low End (2k-17k)', 'Low-to-Medium End (17k-31k)', 'Medium-to-High End (31k-50k)', 'High End (50k+)']\n",
    "\n",
    "# Apply pd.cut with meaningful labels\n",
    "data['milage_bracket'] = pd.cut(data['milage'], bins=milage_brackets, labels=milage_labels, include_lowest=True)\n",
    "data['price_bracket'] = pd.cut(data['price'], bins=price_brackets, labels=price_labels, include_lowest=True)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "grknC-WC3an_"
   },
   "source": [
    "## 3.4. Analysing Accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "id": "Ak3X2ZiLdYL-",
    "outputId": "ef8744eb-e8c0-4c47-ef90-bb8dc92085bf"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='accident', data=data)\n",
    "plt.title('Accident Distribution')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "data['accident'].replace({'None reported': 0, 'At least 1 accident or damage reported': 1}, inplace = True)\n",
    "print(\"NaN records under the 'accident' column: \", len(data[data['accident'].isna()]))\n",
    "\n",
    "data.dropna(subset = ['accident'], inplace = True)\n",
    "\n",
    "sns.heatmap(data[num_features].corr(), annot = True)\n",
    "\n",
    "num_features = ['model_year', 'milage', 'price', 'accident']\n",
    "data[num_features].describe().apply(lambda s: s.apply('{0:.0f}'.format))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Model Year Brackets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_year = 2024\n",
    "\n",
    "# Calculate the car age\n",
    "data['car_age'] = current_year - data['model_year']\n",
    "\n",
    "# Classify into 4 categories\n",
    "data['age_category'] = pd.cut(data['car_age'], bins=[-1, 5, 10, 20, float('inf')], labels=['0-5 years', '6-10 years', '11-20 years', '20+ years'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('cleaned_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gfTS8bg-4RH9"
   },
   "source": [
    "# Data Pre-Processing & Feature Engineering\n",
    "\n",
    "1. Handling Outliers\n",
    "\n",
    "2. Feature Scaling of numeric features & one-hot encoding of categorical features\n",
    "\n",
    "3. Cross Validation\n",
    "\n",
    "4. Hyperaparmeter Tuning through GridSearchCV or RandomSearchCV\n",
    "\n",
    "5. Fit-transform on train data and only transform on test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBqqufmmT-rd"
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define numeric and categorical columns\n",
    "numeric_cols = ['model_year', 'milage', 'accident', 'car_age']\n",
    "categorical_cols = ['brand', 'model', 'fuel_type', 'transmission']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X = data[numeric_cols + categorical_cols]\n",
    "y = data['price']  # Assuming 'price' is the target variable\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocessing for numeric data\n",
    "numeric_transformer = StandardScaler()\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Custom class to add tqdm progress bar support for RandomForest\n",
    "class RandomForestWithProgress(RandomForestRegressor):\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        # Initialize tqdm progress bar\n",
    "        self.n_estimators_ = 0  # Add this attribute for tracking progress\n",
    "        for _ in tqdm(range(self.n_estimators), desc=\"Fitting Random Forest\", leave=True):\n",
    "            super().fit(X, y, sample_weight=sample_weight)\n",
    "            self.n_estimators_ += 1  # Update the estimator count\n",
    "        return self\n",
    "\n",
    "# Create the pipeline with RandomForestRegressor\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestWithProgress(n_estimators=100, random_state=42, warm_start=True))\n",
    "])\n",
    "\n",
    "# Train the model with progress bar\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R² Score: {r2}\")\n",
    "\n",
    "# --- Additional Evaluations and Graphs ---\n",
    "\n",
    "# Feature importance plot\n",
    "feature_names = numeric_cols + list(model.named_steps['preprocessor'].transformers_[1][1].get_feature_names_out(categorical_cols))\n",
    "feature_importances = model.named_steps['regressor'].feature_importances_\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_names, feature_importances)\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Feature Importance in Random Forest\")\n",
    "plt.show()\n",
    "\n",
    "# Residual analysis\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_pred, residuals, alpha=0.6)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.show()\n",
    "\n",
    "# Distribution of residuals\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(residuals, bins=30, edgecolor='k', alpha=0.7)\n",
    "plt.xlabel(\"Residual\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Residuals\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
